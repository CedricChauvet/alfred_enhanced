import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence
from models.model.seq2seq_im_mask import Module as BaseModule
from models.nn import vnn
import numpy as np


class Module(BaseModule):
    """
    Mod√®le avec g√©n√©ration Chain-of-Thought des subgoals
    H√©rite directement de seq2seq_im_mask.Module
    
    Fonctionnalit√©:
    - G√©n√®re les subgoals avant de g√©n√©rer les actions
    - Calcule la loss de pr√©diction des subgoals
    """
    
    def __init__(self, args, vocab):
        """
        Initialisation avec g√©n√©ration CoT des subgoals
        """
        super().__init__(args, vocab)
        
        # ========================================
        # G√âN√âRATION DES SUBGOALS (CoT)
        # ========================================
        
        # Vocabulaire des subgoals (actions high-level)
        self.vocab_subgoal = vocab['action_high']
        
        # Dimension des embeddings de subgoals
        self.demb_subgoal = getattr(args, 'demb_subgoal', args.demb)
        
        # Embeddings des subgoals
        self.emb_subgoal = nn.Embedding(len(self.vocab_subgoal), self.demb_subgoal)
        
        # D√©codeur LSTM pour les subgoals
        # Prend en entr√©e: embedding du subgoal pr√©c√©dent + contexte linguistique
        self.subgoal_decoder = nn.LSTM(
            input_size=self.demb_subgoal + 2*args.dhid,  # embedding + contexte bidirectionnel
            hidden_size=args.dhid,
            num_layers=1,
            batch_first=True
        )
        
        # Couche de projection pour pr√©dire le subgoal suivant
        self.subgoal_proj = nn.Linear(args.dhid, len(self.vocab_subgoal))
        
        # Embedding GO pour d√©marrer la g√©n√©ration (comme dans le d√©codeur d'actions)
        self.subgoal_go = nn.Parameter(torch.Tensor(self.demb_subgoal))
        nn.init.normal_(self.subgoal_go)
        
        # Utiliser les tokens existants du vocabulaire parent
        # self.pad et self.stop_token sont d√©j√† d√©finis dans la classe Base
        
        # Dropout pour le d√©codeur de subgoals
        self.subgoal_dropout = nn.Dropout(getattr(args, 'subgoal_dropout', 0.1))
        
        # Param√®tre pour activer/d√©sactiver la g√©n√©ration de subgoals
        self.use_subgoals = getattr(args, 'use_subgoals', True)
        
        # Param√®tre pour activer/d√©sactiver la loss du current subgoal
        # Mettre √† False si cette loss ne converge pas bien
        self.use_current_subgoal_loss = getattr(args, 'use_current_subgoal_loss', True)
        
        # ========================================
        # PR√âDICTION DU SUBGOAL ACTIF
        # ========================================
        # √Ä chaque timestep, pr√©dit quel subgoal (parmi ceux g√©n√©r√©s) est actif
        # Input: CONTEXTE COMPLET + SIGNAUX DU D√âCODEUR PARENT
        #        - h_t (dhid)
        #        - visual features (dframe)
        #        - action embedding (demb)
        #        - temporal progress (1) - calcul√© (t/max_t)
        #        - üÜï progress_t (1) - sigmoid(self.progress(cont_t)) du d√©codeur parent
        #        - üÜï subgoal_t (1) - sigmoid(self.subgoal(cont_t)) du d√©codeur parent
        # Output: distribution sur les subgoals g√©n√©r√©s
        
        # Calculer la dimension du contexte complet pour le pr√©dicteur
        # +3 car: +1 progress calcul√©, +1 progress_t du parent, +1 subgoal_t du parent
        context_dim = 2*args.dhid + args.dframe + args.demb + 3
        
        # MLP plus profond pour mieux capturer les patterns temporels et multimodaux
        self.current_subgoal_scorer = nn.Sequential(
            nn.Linear(context_dim, args.dhid),
            nn.ReLU(),
            nn.Dropout(getattr(args, 'current_subgoal_dropout', 0.1)),
            nn.Linear(args.dhid, args.dhid),
            nn.ReLU(),
            nn.Linear(args.dhid, args.dhid)  # Output: dhid
        )
        self.current_subgoal_dropout = nn.Dropout(getattr(args, 'current_subgoal_dropout', 0.1))
        
        print(f"‚úÖ Subgoal CoT decoder initialized with vocab size: {len(self.vocab_subgoal)}")
        print(f"‚úÖ Current subgoal predictor initialized with:")
        print(f"   - Multi-layer MLP (3 layers)")
        print(f"   - FULL CONTEXT: h_t + visual + action")
        print(f"   - üÜï PARENT DECODER SIGNALS: progress_t + subgoal_t")
        print(f"   - Input dim: {2*args.dhid + args.dframe + args.demb + 3}")
        print(f"     (context={2*args.dhid + args.dframe + args.demb}, +3 signals)")
    
    
    def generate_subgoals(self, enc_lang, cont_lang, max_subgoals=10, sampling=False, temperature=1.0):
        """
        G√©n√®re une s√©quence de subgoals avec approche Chain-of-Thought
        
        Args:
            enc_lang: Encodage linguistique complet [batch, seq_len, dhid*2]
            cont_lang: Contexte linguistique (dernier √©tat cach√©) [batch, dhid*2]
            max_subgoals: Nombre maximum de subgoals √† g√©n√©rer
            sampling: Si True, √©chantillonne; sinon prend argmax
            temperature: Temp√©rature pour le sampling (plus √©lev√© = plus al√©atoire)
        
        Returns:
            subgoals: Liste de subgoals pr√©dits [batch, num_subgoals]
            subgoal_logits: Logits pour chaque subgoal [batch, num_subgoals, vocab_size]
            subgoal_embeddings: Embeddings des subgoals [batch, num_subgoals, demb_subgoal]
        """
        device = next(self.parameters()).device
        batch_size = enc_lang.size(0)
        
        # Liste pour stocker les pr√©dictions
        predicted_subgoals = []
        subgoal_logits_list = []
        subgoal_embeddings_list = []
        
        # √âtat cach√© initial du d√©codeur (d√©riv√© du contexte linguistique)
        # R√©duire la dimension de cont_lang (dhid*2) vers dhid
        h_t = cont_lang[:, :self.args.dhid].unsqueeze(0).contiguous()  # [1, batch, dhid]
        c_t = torch.zeros_like(h_t)  # √âtat de cellule initial
        
        # Embedding de d√©marrage GO pour tous les exemples du batch
        emb_t = self.subgoal_go.repeat(batch_size, 1)  # [batch, demb_subgoal]
        current_token = None  # Premi√®re it√©ration utilise GO, pas un token
        
        # G√©n√©ration autoregressif des subgoals
        for step in range(max_subgoals):
            # Embedding du token actuel (GO pour la premi√®re it√©ration, sinon embedding du token pr√©c√©dent)
            if current_token is None:
                # Premi√®re it√©ration: utiliser GO
                emb_current = emb_t
            else:
                # It√©rations suivantes: utiliser l'embedding du token pr√©dit
                emb_current = self.emb_subgoal(current_token)  # [batch, demb_subgoal]
            
            # Concat√©ner avec le contexte linguistique
            decoder_input = torch.cat([emb_current, cont_lang], dim=-1)  # [batch, demb_subgoal + dhid*2]
            decoder_input = decoder_input.unsqueeze(1)  # [batch, 1, demb_subgoal + dhid*2]
            
            # Passer dans le LSTM d√©codeur
            lstm_out, (h_t, c_t) = self.subgoal_decoder(decoder_input, (h_t, c_t))
            
            # Appliquer dropout
            lstm_out = self.subgoal_dropout(lstm_out.squeeze(1))  # [batch, dhid]
            
            # Pr√©dire le prochain subgoal
            logits = self.subgoal_proj(lstm_out)  # [batch, vocab_size]
            
            # √âchantillonnage ou argmax
            if sampling:
                # √âchantillonnage avec temp√©rature
                probs = F.softmax(logits / temperature, dim=-1)
                next_token = torch.multinomial(probs, num_samples=1).squeeze(-1)
            else:
                # Greedy decoding
                next_token = logits.argmax(dim=-1)
            
            # Stocker les r√©sultats
            predicted_subgoals.append(next_token)
            subgoal_logits_list.append(logits)
            subgoal_embeddings_list.append(emb_current)
            
            # V√©rifier si tous les exemples du batch ont g√©n√©r√© <<stop>>
            if (next_token == self.stop_token).all():
                break
            
            # Mettre √† jour le token actuel pour le prochain step
            current_token = next_token
        
        # Stacker les r√©sultats
        subgoals = torch.stack(predicted_subgoals, dim=1)  # [batch, num_subgoals]
        subgoal_logits = torch.stack(subgoal_logits_list, dim=1)  # [batch, num_subgoals, vocab_size]
        subgoal_embeddings = torch.stack(subgoal_embeddings_list, dim=1)  # [batch, num_subgoals, demb_subgoal]
        
        return subgoals, subgoal_logits, subgoal_embeddings
    
    
    def compute_subgoal_loss(self, predicted_logits, ground_truth_subgoals):
        """
        Calcule la loss pour la pr√©diction des subgoals
        
        Args:
            predicted_logits: Logits pr√©dits [batch, num_subgoals, vocab_size]
            ground_truth_subgoals: Subgoals ground truth [batch, num_subgoals]
        
        Returns:
            loss: Cross-entropy loss pour les subgoals
        """
        device = next(self.parameters()).device
        
        # Reshape pour le calcul de cross-entropy
        pred_flat = predicted_logits.view(-1, predicted_logits.size(-1))  # [batch*num_subgoals, vocab_size]
        gt_flat = ground_truth_subgoals.view(-1)  # [batch*num_subgoals]
        
        # Masque pour ignorer le padding
        pad_mask = (gt_flat != self.pad)
        
        # Cross-entropy loss
        loss = F.cross_entropy(pred_flat, gt_flat, reduction='none')
        loss = loss * pad_mask.float()
        loss = loss.sum() / pad_mask.sum()
        
        return loss
    
    
    def predict_current_subgoal(self, context, subgoal_embeddings, timestep=None, progress=None, 
                                progress_signal=None, subgoal_signal=None):
        """
        Pr√©dit quel subgoal (parmi ceux g√©n√©r√©s) est actuellement actif
        
        UTILISE LE CONTEXTE COMPLET + SIGNAUX DU BASELINE:
        - Contexte multimodal (h_t + visual + action)
        - Information temporelle (progress)
        - üÜï self.progress du d√©codeur baseline (% t√¢che accomplie)
        - üÜï self.subgoal du d√©codeur baseline (% subgoals compl√©t√©s)
        
        Args:
            context: Contexte complet du d√©codeur [batch, dhid+dhid+dframe+demb]
            subgoal_embeddings: Embeddings des subgoals g√©n√©r√©s [batch, num_subgoals, demb_subgoal]
            timestep: Timestep actuel (optionnel)
            progress: Progression dans la s√©quence 0-1 (optionnel)
            progress_signal: Signal self.progress du baseline [batch, 1] (optionnel)
            subgoal_signal: Signal self.subgoal du baseline [batch, 1] (optionnel)
        
        Returns:
            current_subgoal_logits: Scores pour chaque subgoal [batch, num_subgoals]
            current_subgoal_idx: Indice du subgoal le plus probable [batch]
            current_subgoal_probs: Probabilit√©s pour chaque subgoal [batch, num_subgoals]
        """
        device = next(self.parameters()).device
        batch_size = context.size(0)
        num_subgoals = subgoal_embeddings.size(1)
        
        # ========================================
        # 1. ENRICHIR L'INPUT AVEC TOUTES LES INFOS
        # ========================================
        context_input = context  # [batch, dhid+dhid+dframe+demb]
        
        # Liste des features additionnelles √† concat√©ner
        additional_features = []
        
        # Progression temporelle (calcul√©e)
        if progress is not None:
            if isinstance(progress, (int, float)):
                progress_tensor = torch.full((batch_size, 1), progress, device=device)
            else:
                progress_tensor = progress.view(batch_size, 1)
            additional_features.append(progress_tensor)
        
        # üÜï Signal self.progress du baseline (pr√©diction du d√©codeur)
        if progress_signal is not None:
            # progress_signal est d√©j√† [batch, 1]
            additional_features.append(progress_signal)
        
        # üÜï Signal self.subgoal du baseline (proportion de subgoals compl√©t√©s)
        if subgoal_signal is not None:
            # subgoal_signal est d√©j√† [batch, 1]
            additional_features.append(subgoal_signal)
        
        # Concat√©ner toutes les features
        if len(additional_features) > 0:
            context_input = torch.cat([context] + additional_features, dim=-1)
        
        # ========================================
        # 2. PROJETER AVEC MLP PLUS PROFOND
        # ========================================
        # Utiliser le scorer (MLP 3-layers)
        h_proj = self.current_subgoal_scorer(context_input)  # [batch, dhid]
        h_proj = self.current_subgoal_dropout(h_proj)
        
        # ========================================
        # 3. PROJETER LES SUBGOALS DANS LE M√äME ESPACE
        # ========================================
        # Si demb_subgoal != dhid, on doit projeter
        if self.demb_subgoal != self.args.dhid:
            # Cr√©er une projection si elle n'existe pas
            if not hasattr(self, 'subgoal_emb_to_dhid'):
                self.subgoal_emb_to_dhid = nn.Linear(self.demb_subgoal, self.args.dhid).to(device)
            subgoal_proj = self.subgoal_emb_to_dhid(subgoal_embeddings)  # [batch, num_subgoals, dhid]
        else:
            subgoal_proj = subgoal_embeddings
        
        # ========================================
        # 4. CALCULER LA SIMILARIT√â
        # ========================================
        # Produit scalaire pour mesurer la similarit√©
        # h_proj: [batch, dhid] -> [batch, 1, dhid]
        h_expanded = h_proj.unsqueeze(1)  # [batch, 1, dhid]
        
        # Similarity: [batch, 1, dhid] @ [batch, dhid, num_subgoals] -> [batch, 1, num_subgoals]
        similarity = torch.bmm(h_expanded, subgoal_proj.transpose(1, 2))
        current_subgoal_logits = similarity.squeeze(1)  # [batch, num_subgoals]
        
        # Softmax pour obtenir des probabilit√©s
        current_subgoal_probs = F.softmax(current_subgoal_logits, dim=-1)  # [batch, num_subgoals]
        
        # Subgoal le plus probable
        current_subgoal_idx = current_subgoal_probs.argmax(dim=-1)  # [batch]
        
        return current_subgoal_logits, current_subgoal_idx, current_subgoal_probs
    
    
    
    def forward(self, feat, max_decode=300):
        """
        Forward pass avec g√©n√©ration de subgoals CoT et tracking du subgoal actif
        
        Processus:
        1. Encoder le langage (instructions + goal)
        2. G√©n√©rer les subgoals avec CoT
        3. G√©n√©rer les actions bas niveau
        4. √Ä chaque timestep: pr√©dire quel subgoal est actif
        """
        device = next(self.parameters()).device
        
        # Encoder le langage (appel √† la m√©thode parente)
        cont_lang, enc_lang = self.encode_lang(feat)
        
        # üéØ G√âN√âRATION DES SUBGOALS (Chain-of-Thought)
        if self.use_subgoals and not self.test_mode:
            subgoals, subgoal_logits, subgoal_embeddings = self.generate_subgoals(
                enc_lang, cont_lang, 
                max_subgoals=self.max_subgoals
            )
            
            # Stocker dans feat pour utilisation ult√©rieure et calcul de loss
            feat['predicted_subgoals'] = subgoals
            feat['subgoal_logits'] = subgoal_logits
            feat['subgoal_embeddings'] = subgoal_embeddings
        
        # ========================================
        # G√âN√âRATION DES ACTIONS avec tracking du subgoal actif
        # ========================================
        if self.use_subgoals and not self.test_mode and 'subgoal_embeddings' in feat:
            # Mode avec tracking: on doit d√©coder manuellement pour tracker
            # Initialiser les √©tats
            e_t = self.dec.go.repeat(enc_lang.size(0), 1)
            state_t = cont_lang, torch.zeros_like(cont_lang)
            
            # Listes pour stocker les outputs
            outputs = []
            masks = []
            current_subgoal_predictions = []  # üéØ NOUVEAU: track des subgoals actifs
            subgoal_monitoring = []  # Pour self.subgoal
            progress_monitoring = []  # Pour self.progress
            
            # S√©quence d'actions ground truth pour teacher forcing
            actions = feat['action_low'] if self.dec.teacher_forcing and 'action_low' in feat else None
            
            # Boucle de d√©codage
            max_t = actions.size(1) if actions is not None else min(max_decode, feat['frames'].shape[1])
            
            for t in range(max_t):
                # Frames √† ce timestep
                frames_t = feat['frames'][:, t] if t < feat['frames'].size(1) else feat['frames'][:, -1]
                
                # D√©coder une action
                out_t, mask_t, state_t, *extra = self.dec.step(enc_lang, frames_t, e_t=e_t, state_tm1=state_t)
                
                outputs.append(out_t)
                masks.append(mask_t)
                
                # üéØ R√âCUP√âRER LES SIGNAUX DU D√âCODEUR PARENT
                # extra = [lang_attn_t, subgoal_t, progress_t]
                # subgoal_t et progress_t sont d√©j√† calcul√©s par le d√©codeur parent:
                #   progress_t = sigmoid(self.progress(cont_t))
                #   subgoal_t = sigmoid(self.subgoal(cont_t))
                progress_t = None
                subgoal_t = None
                if self.subgoal_monitoring and len(extra) >= 3:
                    subgoal_t = extra[1]  # sigmoid(self.subgoal(cont_t)) du parent
                    progress_t = extra[2]  # sigmoid(self.progress(cont_t)) du parent
                    subgoal_monitoring.append(subgoal_t)
                    progress_monitoring.append(progress_t)
                
                # üéØ PR√âDIRE LE SUBGOAL ACTIF √† ce timestep
                h_t, c_t = state_t
                
                # üîç ENCODER LES FEATURES VISUELLES
                # frames_t est [batch, channels, height, width] - il faut l'encoder !
                vis_feat_t = self.dec.vis_encoder(frames_t)  # [batch, dframe]
                
                # Cr√©er le contexte complet (comme dans ConvFrameMaskDecoderProgressMonitor)
                # cont_t contient: h_t + visual_features + action_embedding
                cont_t = torch.cat([h_t, vis_feat_t, e_t], dim=1)  
                # Dimension: [batch, 2*dhid + dframe + demb] = [batch, 256+2048+100] = [batch, 2404]
                
                # Calculer la progression temporelle (calcul√©e na√Øvement)
                temporal_progress = t / max_t  # Entre 0 et 1
                
                current_logits, current_idx, current_probs = self.predict_current_subgoal(
                    cont_t,  # Contexte complet
                    feat['subgoal_embeddings'],
                    timestep=t,
                    progress=temporal_progress,     # Calcul√© (t/max_t)
                    progress_signal=progress_t,     # üÜï Du d√©codeur parent (d√©j√† entra√Æn√©!)
                    subgoal_signal=subgoal_t        # üÜï Du d√©codeur parent (d√©j√† entra√Æn√©!)
                )
                current_subgoal_predictions.append(current_logits)
                
                # üîç LOGGING OCCASIONNEL (pour debug)
                # Afficher quelques pr√©dictions pour v√©rifier que √ßa a du sens
                if self.training and t % 20 == 0 and torch.rand(1).item() < 0.005:  # 0.5% des cas
                    # FIXED: Format strings corrects (pas de :.2f dans if/else)
                    prog_val = progress_t[0].item() if progress_t is not None else None
                    subg_val = subgoal_t[0].item() if subgoal_t is not None else None
                    prog_str = f"{prog_val:.2f}" if prog_val is not None else "N/A"
                    subg_str = f"{subg_val:.2f}" if subg_val is not None else "N/A"
                    print(f"üîç [t={t:3d}] Predicted subgoal: {current_idx[0].item()} "
                          f"probs={current_probs[0].tolist()} "
                          f"progress_t={prog_str} subgoal_t={subg_str}")
                
                # üé® CR√âER LE CONTEXTE DU SUBGOAL ACTIF (Hard Selection)
                # S√©lectionner directement l'embedding du subgoal pr√©dit (au lieu de moyenne pond√©r√©e)
                batch_indices = torch.arange(feat['subgoal_embeddings'].size(0), device=device)
                subgoal_ctx = feat['subgoal_embeddings'][batch_indices, current_idx]  # [batch, demb_subgoal]
                # Pour l'instant on le calcule juste, on l'injectera dans le d√©codeur plus tard
                
                # Teacher forcing ou utiliser la pr√©diction
                if self.dec.teacher_forcing and actions is not None and t < actions.size(1):
                    e_t = self.dec.emb(actions[:, t])
                else:
                    e_t = self.dec.emb(out_t.max(1)[1])
                
                # Arr√™ter si toutes les s√©quences ont g√©n√©r√© stop
                if not self.dec.teacher_forcing:
                    predictions = out_t.max(1)[1]
                    if (predictions == self.stop_token).all():
                        break
            
            # Pr√©parer les outputs
            out = {}
            out['out_action_low'] = torch.stack(outputs, dim=1)  # [batch, seq_len, vocab_size]
            out['out_action_low_mask'] = torch.stack(masks, dim=1)  # [batch, seq_len, h, w]
            out['predicted_subgoals'] = subgoals
            out['subgoal_logits'] = subgoal_logits
            out['current_subgoal_logits'] = torch.stack(current_subgoal_predictions, dim=1)  # [batch, seq_len, num_subgoals]
            
            # ‚úÖ IMPORTANT: Copier vers feat pour extract_preds
            feat['out_action_low'] = out['out_action_low']
            feat['out_action_low_mask'] = out['out_action_low_mask']
            
            # Ajouter les outputs de monitoring si activ√©
            if self.subgoal_monitoring and len(subgoal_monitoring) > 0:
                out['out_subgoal'] = torch.stack(subgoal_monitoring, dim=1)
                out['out_progress'] = torch.stack(progress_monitoring, dim=1)
                feat['out_subgoal'] = out['out_subgoal']
                feat['out_progress'] = out['out_progress']
        
        else:
            # Mode sans tracking: appeler simplement le parent
            out = super().forward(feat, max_decode=max_decode)
            
            # Ajouter les subgoals √† la sortie si disponibles
            if self.use_subgoals and not self.test_mode:
                out['predicted_subgoals'] = subgoals
                out['subgoal_logits'] = subgoal_logits
        
        return out
    
    
    def compute_loss(self, out, batch, feat):
        """
        Calcule la loss totale incluant:
        - Loss des actions (baseline)
        - Loss des masques (baseline)  
        - Loss des subgoals (CoT)
        - Loss du current subgoal (tracking)
        """
        # Loss du mod√®le parent (actions + masques)
        losses = super().compute_loss(out, batch, feat)
        
        # Ajouter la loss des subgoals si activ√©e
        if self.use_subgoals and 'subgoal_logits' in out and 'action_high' in feat:
            subgoal_loss = self.compute_subgoal_loss(
                out['subgoal_logits'],
                feat['action_high']
            )
            
            # Poids pour la loss des subgoals
            subgoal_loss_weight = getattr(self.args, 'subgoal_loss_wt', 1.0)
            losses['subgoal'] = subgoal_loss * subgoal_loss_weight
        
        # üéØ NOUVEAU: Loss pour la pr√©diction du subgoal actif
        if (self.use_subgoals and self.use_current_subgoal_loss and 
            'current_subgoal_logits' in out and 'low_to_high_idx' in feat):
            current_subgoal_loss = self.compute_current_subgoal_loss(
                out['current_subgoal_logits'],
                feat['low_to_high_idx']
            )
            
            # Poids pour la loss du current subgoal (r√©duit pour √©viter de dominer)
            current_subgoal_loss_weight = getattr(self.args, 'current_subgoal_loss_wt', 0.1)  # 0.1 au lieu de 0.5
            losses['current_subgoal'] = current_subgoal_loss * current_subgoal_loss_weight
            
            # üìä NOUVEAU: Calculer l'accuracy comme m√©trique (pas de gradient)
            with torch.no_grad():
                # Pr√©dictions: argmax des logits
                pred_idx = out['current_subgoal_logits'].argmax(dim=-1)  # [batch, seq_len]
                gt_idx = feat['low_to_high_idx']  # [batch, seq_len]
                
                # Masque pour ignorer le padding
                valid_mask = (gt_idx != self.pad)
                
                # Accuracy
                correct = (pred_idx == gt_idx) & valid_mask
                accuracy = correct.sum().float() / (valid_mask.sum().float() + 1e-8)
                
                # ENHANCED: Stocker comme tensor (coh√©rent avec les autres losses)
                # Note: seq2seq.py appelle .item() sur toutes les valeurs, donc on garde le tensor
                losses['current_subgoal_accuracy'] = accuracy  # Tensor, pas .item()
        
        return losses
    
    
    def compute_current_subgoal_loss(self, predicted_logits, ground_truth_idx):
        """
        Loss pour la pr√©diction du subgoal actif √† chaque timestep
        
        Args:
            predicted_logits: Logits pour chaque subgoal [batch, seq_len, num_subgoals]
            ground_truth_idx: Indice du subgoal qui devrait √™tre actif [batch, seq_len]
        
        Returns:
            loss: Cross-entropy loss
        """
        # Reshape pour le calcul de cross-entropy
        batch_size, seq_len, num_subgoals = predicted_logits.size()
        pred_flat = predicted_logits.view(-1, num_subgoals)  # [batch*seq_len, num_subgoals]
        gt_flat = ground_truth_idx.view(-1)  # [batch*seq_len]
        
        # Masque pour ignorer le padding
        pad_mask = (gt_flat != self.pad)
        
        # Cross-entropy loss
        loss = F.cross_entropy(pred_flat, gt_flat, reduction='none')
        loss = loss * pad_mask.float()
        loss = loss.sum() / (pad_mask.sum() + 1e-8)
        
        return loss
    
    
    def featurize(self, batch, load_mask=True, load_frames=True):
        """
        Tensorize batch avec ajout de low_to_high_idx pour la loss du current subgoal
        """
        # Appeler la m√©thode parente
        feat = super().featurize(batch, load_mask=load_mask, load_frames=load_frames)
        
        # Ajouter l'alignement action -> subgoal pour la loss
        if not self.test_mode and self.use_subgoals:
            device = next(self.parameters()).device
            low_to_high_indices = []
            
            for ex in batch:
                if 'low_to_high_idx' in ex['num']:
                    # D√©j√† disponible dans les donn√©es
                    low_to_high_indices.append(ex['num']['low_to_high_idx'])
                else:
                    # Cr√©er un mapping par d√©faut (chaque action appartient au subgoal 0)
                    num_actions = len(ex['num']['action_low'])
                    low_to_high_indices.append([0] * num_actions)
            
            # Tensorize et pad
            seqs = [torch.tensor(indices, device=device, dtype=torch.long) for indices in low_to_high_indices]
            feat['low_to_high_idx'] = pad_sequence(seqs, batch_first=True, padding_value=self.pad)
        
        return feat



if __name__ == "__main__":
    print("‚úÖ CoT Subgoals module cr√©√© avec succ√®s!")
    print("üìù Fonctionnalit√©s:")
    print("   - generate_subgoals(): G√©n√©ration Chain-of-Thought des subgoals")
    print("   - compute_subgoal_loss(): Loss de pr√©diction des subgoals")
    print("   - Int√©gration avec le mod√®le baseline seq2seq_im_mask")